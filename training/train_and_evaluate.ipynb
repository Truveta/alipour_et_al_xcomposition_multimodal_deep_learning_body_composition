{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Literal\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer  # This is necessary to use IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import copy\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy import stats\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = pathlib.Path('./training-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load the clinical data stored in \"clinical.csv\" and impute missing data\n",
    "\n",
    "clinical_df = pd.read_csv('./clinical.csv', index_col=0)\n",
    "\n",
    "# Encode 'Sex' as a binary variable (1 for Male, 0 for Female)\n",
    "clinical_df['Sex'] = np.where(clinical_df['Sex'] == 'Male', 1, clinical_df['Sex'])\n",
    "clinical_df['Sex'] = np.where(clinical_df['Sex'] == 'Female', 0, clinical_df['Sex'])\n",
    "\n",
    "\n",
    "# Use IterativeImputer instead of SimpleImputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Columns to impute (excluding 'PatientID')\n",
    "columns_to_impute = clinical_df.columns.difference(['PatientID'])\n",
    "\n",
    "# Use IterativeImputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Apply the imputer only to the columns that need imputation\n",
    "clinical_df[columns_to_impute] = imputer.fit_transform(clinical_df[columns_to_impute])\n",
    "\n",
    "clinical_df_orig = clinical_df.copy()\n",
    "#clinical_df.to_csv(\"training-data/snapshots/BodyComposition_2/output/clinical_imputed.csv\")\n",
    "\n",
    "clinical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load the body composition data stored in \"body_composition.csv\"\n",
    "\n",
    "targets_df_new = pd.read_csv('./body_composition.csv', index_col = 0)\n",
    "targets_df_new = targets_df_new.loc[targets_df_new.index.isin(clinical_df.PatientID)]\n",
    "targets_df_new = targets_df_new.loc[targets_df_new.PersonId.isin(clinical_df.PatientID)]\n",
    "targets_df_new = targets_df_new.rename(columns={'PersonId': 'PatientID'})\n",
    "targets_df_new = pd.merge(clinical_df[['PatientID','Height_in_meters']], targets_df_new, on='PatientID', how='right')\n",
    "targets_df_new = targets_df_new.set_index('PatientID')\n",
    "#targets_df_new = targets_df_new.set_index('PersonId')\n",
    "if 'VisceralFatArea' in targets_df_new.columns:\n",
    "    targets_df_new['VisceralFatIndex'] = targets_df_new['VisceralFatArea']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['SkeletalMuscleIndex'] = targets_df_new['SkeletalMuscleArea']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['SubcutaneousFatIndex'] = targets_df_new['SubcutaneousFatArea']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['FatFreeIndex'] = targets_df_new['FatFreeArea']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "if 'VisceralFatVolume' in targets_df_new.columns:\n",
    "    targets_df_new['VisceralFatIndex'] = targets_df_new['VisceralFatVolume']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['SkeletalMuscleIndex'] = targets_df_new['SkeletalMuscleVolume']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['SubcutaneousFatIndex'] = targets_df_new['SubcutaneousFatVolume']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "    targets_df_new['FatFreeIndex'] = targets_df_new['FatFreeVolume']/(targets_df_new['Height_in_meters']*targets_df_new['Height_in_meters'])\n",
    "targets_df_new = targets_df_new.drop(columns = ['Height_in_meters'])\n",
    "targets_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Load the table with radiograph paths\n",
    "radiograph_paths = pd.read_csv('./radiograph_paths',index_col = 0)\n",
    "radiograph_paths['DX_path'] = radiograph_paths['DX_path']\n",
    "radiograph_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloaders\n",
    "train_df, test_df = train_test_split(\n",
    "    targets_df_new, test_size=0.2, random_state=25\n",
    ")\n",
    "\n",
    "train_df = targets_df_new.loc[targets_df_new.index.isin(train_df.index)]\n",
    "test_df = targets_df_new.loc[targets_df_new.index.isin(test_df.index)]\n",
    "\n",
    "### Confirm no shared Ids\n",
    "assert np.sum(test_df.index.isin(train_df.index)) == 0\n",
    "print('No data-leak detected. yay...')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    normalized_image = (image - min_val) / (max_val - min_val) * 255\n",
    "    return normalized_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def to_tensor(img):\n",
    "    # Convert PIL Image to NumPy array\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    # Transpose dimensions to (C, H, W) and normalize pixel values to [0, 1]\n",
    "    #img = torch.tensor(img.transpose((2, 0, 1)) / np.max(img) - np.min(img))\n",
    "    return img\n",
    "\n",
    "def pad_to_square(img):\n",
    "    # Calculate the mean value of the image\n",
    "    mean_val = img.mean()\n",
    "    \n",
    "    # Determine the size of padding\n",
    "    h, w = img.shape\n",
    "    if h > w:\n",
    "        padding = ((0, 0), ((h - w) // 2, (h - w + 1) // 2))\n",
    "    else:\n",
    "        padding = (((w - h) // 2, (w - h + 1) // 2), (0, 0))\n",
    "    #print(padding)\n",
    "    # Pad the image to make it square\n",
    "    img_padded = np.pad(img, padding, mode='constant', constant_values=mean_val)\n",
    "    return img_padded\n",
    "\n",
    "image_size = 512\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(image_size, image_size)),\n",
    "    #transforms.Resize(size=(256, 256)),  # Resize the image to 256x256 pixels\n",
    "    #transforms.RandomCrop(size=(224, 224)),  # Randomly crop the image to 224x224 pixels\n",
    "    transforms.RandomRotation(degrees=10),  # Randomly rotate the image by up to 15 degrees\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    #transforms.RandomVerticalFlip(),  # Randomly flip the image vertically\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Random color jitter\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(image_size, image_size)),  # Resize the image to 256x256 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryDictDatasetV2(Dataset):\n",
    "    def __init__(self, targets_df: pd.DataFrame, cxr_paths_df: pd.DataFrame, clinical_df: pd.DataFrame, transform=None, pad = True, normalize: Literal['minmax', 'zscore'] = \"minmax\", random_image = True):\n",
    "        self.targets_df = targets_df\n",
    "        self.cxr_paths_df = cxr_paths_df\n",
    "        self.clinical_df = clinical_df.set_index('PatientID')\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "        self.pad = pad\n",
    "        self.target_cols = targets_df.columns.to_list()\n",
    "        self.trimmed_targets_df = targets_df\n",
    "        self.images = {}\n",
    "        self.random_image = random_image\n",
    "        for pt_id in tqdm(self.targets_df.index):\n",
    "            if pt_id in self.cxr_paths_df.index.to_list():\n",
    "                self.images[pt_id] = []\n",
    "                np_files = self.cxr_paths_df.loc[pt_id].DX_good\n",
    "                np_files_reverse = self.cxr_paths_df.loc[pt_id].DX_PA_reverse\n",
    "                if np_files != None:\n",
    "                    for file in np_files:\n",
    "                        self.images[pt_id].append(np.load(file))\n",
    "                if np_files_reverse != None:\n",
    "                    for file in np_files_reverse:\n",
    "                        self.images[pt_id].append(-1 * (np.load(file)))\n",
    "            else:\n",
    "                if pt_id in self.targets_df.index:\n",
    "                    self.targets_df = self.targets_df.drop(index = pt_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pt_id = self.targets_df.index[idx]\n",
    "        if self.random_image:\n",
    "            image = random.choice(self.images[pt_id])\n",
    "        else:\n",
    "            image = self.images[pt_id][0]\n",
    "        if self.normalize == \"zscore\":\n",
    "            std = np.std(image)\n",
    "            mean = np.mean(image)\n",
    "            image = (image - mean)/std\n",
    "        elif self.normalize == \"minmax\":\n",
    "            image = (image - np.min(image)) / (np.max(image) - np.min(image))  # Normalize\n",
    "        else:\n",
    "            pass\n",
    "        if self.pad:\n",
    "            image = pad_to_square(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        target = self.trimmed_targets_df.loc[pt_id].values.astype(np.float32)\n",
    "        clinical_vars = torch.tensor(self.clinical_df.loc[pt_id].fillna(0).values, dtype=torch.float32).flatten()\n",
    "        return {\n",
    "            'image' : image,\n",
    "            'target' : target,\n",
    "            'clinical': clinical_vars,\n",
    "            'id' : pt_id,\n",
    "        }\n",
    "\n",
    "    def set_target_columns(self, target_cols):\n",
    "        self.target_cols =  target_cols\n",
    "        self.trimmed_targets_df = self.targets_df[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_train_df = clinical_df.loc[clinical_df.PatientID.isin(train_df.index)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "list_cont_features = ['XRAge', 'Height_in_meters', 'Weight_in_kg']\n",
    "scaler.fit(clinical_train_df[list_cont_features])\n",
    "clinical_df[list_cont_features] = scaler.transform(clinical_df[list_cont_features])\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "target_scaler.fit(train_df)\n",
    "scaled_train_array = target_scaler.transform(train_df)\n",
    "scaled_train_df = pd.DataFrame(scaled_train_array, columns=train_df.columns, index=train_df.index)\n",
    "scaled_test_array= target_scaler.transform(test_df)\n",
    "scaled_test_df = pd.DataFrame(scaled_test_array, columns=train_df.columns, index=test_df.index)\n",
    "\n",
    "train_minmax_dataset = InMemoryDictDatasetV2(scaled_train_df, cleaned_xr_v2, clinical_df, transform=transform, pad = False, normalize = \"minmax\", random_image = True)\n",
    "test_minmax_dataset = InMemoryDictDatasetV2(scaled_test_df, cleaned_xr_v2, clinical_df, transform=test_transform, pad = False, normalize = \"minmax\", random_image = False)\n",
    "\n",
    "train_zscore_dataset = InMemoryDictDatasetV2(scaled_train_df, cleaned_xr_v2, clinical_df, transform=transform, pad = False, normalize = \"zscore\", random_image = True)\n",
    "test_zscore_dataset = InMemoryDictDatasetV2(scaled_test_df, cleaned_xr_v2, clinical_df, transform=test_transform, pad = False, normalize = \"zscore\", random_image = False)\n",
    "\n",
    "\n",
    "# plt.imshow(normalize_image(test_dataset[0]['image'].squeeze().numpy()), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "train: {len(train_minmax_dataset)}\n",
    "test: {len(test_minmax_dataset)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "# plt.imshow(normalize_image(test_dataset[2]['image'].squeeze().numpy()), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel_EarlyFusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                 base_model,\n",
    "                 output_size,\n",
    "                 num_additional_features,\n",
    "                 clin_dropout = 0,\n",
    "                 image_dropout = 0,\n",
    "                ):\n",
    "        super(RegressionModel_EarlyFusion, self).__init__()\n",
    "        self.model = base_model\n",
    "        self.model.conv1 = nn.Conv2d(1, self.model.conv1.out_channels,\n",
    "                                     kernel_size=self.model.conv1.kernel_size,\n",
    "                                     stride=self.model.conv1.stride,\n",
    "                                     padding=self.model.conv1.padding,\n",
    "                                     bias=False) \n",
    "\n",
    "\n",
    "        num_resnet_features = self.model.fc.in_features\n",
    "        self.clin_fc = nn.Linear(num_additional_features, image_size*image_size)\n",
    "        \n",
    "        self.fc = nn.Linear(num_resnet_features, output_size)\n",
    "        self.model.fc = nn.Identity()\n",
    "        \n",
    "        self.clin_dropout = clin_dropout\n",
    "        self.image_dropout = image_dropout\n",
    "\n",
    "        \n",
    "    def forward(self, x_image, x_clinical):\n",
    "        clin_out = self.clin_fc(x_clinical)\n",
    "        clin_out = clin_out.view(-1, 1, image_size, image_size)\n",
    "        x_image = x_image.view(-1, 1, image_size, image_size)\n",
    "\n",
    "        if self.training:            \n",
    "            dropout_mask = torch.bernoulli(torch.full((clin_out.size(0), clin_out.size(1)), 1 - self.clin_dropout)).to(clin_out.device)\n",
    "            dropout_mask = dropout_mask.unsqueeze(2).unsqueeze(3)  # Reshape mask to match (batch_size, num_channels, 1, 1)\n",
    "            clin_out = clin_out * dropout_mask  # Apply mask to input tensor\n",
    "           \n",
    "        #combined = torch.cat((x_image, clin_out), dim=1)\n",
    "        combined = x_image + clin_out\n",
    "        resnet_out = self.model(combined)\n",
    "        output = self.fc(resnet_out)\n",
    "        #output = self.final_activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel_InterFusion(nn.Module):\n",
    "    def __init__(self, base_model,\n",
    "                 output_size,\n",
    "                 num_additional_features,\n",
    "                 clin_dropout = 0,\n",
    "                 image_dropout = 0,\n",
    "                 freeze_image_net = False,\n",
    "                 concatenate_modes = False,\n",
    "                ):\n",
    "        super(RegressionModel_InterFusion, self).__init__()\n",
    "        self.model = base_model\n",
    "        self.model.conv1 = nn.Conv2d(1, self.model.conv1.out_channels,\n",
    "                                     kernel_size=self.model.conv1.kernel_size,\n",
    "                                     stride=self.model.conv1.stride,\n",
    "                                     padding=self.model.conv1.padding,\n",
    "                                     bias=False) \n",
    "\n",
    "        if freeze_image_net:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_resnet_features = self.model.fc.in_features\n",
    "        #print(num_resnet_features)\n",
    "        self.clin_fc = nn.Linear(num_additional_features, num_resnet_features)\n",
    "        #self.fc = nn.Linear(num_resnet_features + num_additional_features, output_size)\n",
    "        self.fc = nn.Linear(num_resnet_features, output_size)\n",
    "        self.model.fc = nn.Identity()\n",
    "        #self.final_activation = nn.LeakyReLU(0.1)\n",
    "        self.clin_dropout = clin_dropout\n",
    "        self.image_dropout = image_dropout\n",
    "        self.concatenate_modes = concatenate_modes \n",
    "        if concatenate_modes:\n",
    "            print(\"concatenating instead of adding.\")\n",
    "            self.fc_con = nn.Linear(num_resnet_features*2, output_size)\n",
    "        \n",
    "    def forward(self, x_image, x_clinical):\n",
    "        if self.concatenate_modes:\n",
    "            resnet_out = self.model(x_image)\n",
    "            clin_fc_out = self.clin_fc(x_clinical)\n",
    "            output = self.fc_con(torch.cat([resnet_out, clin_fc_out], dim =1))\n",
    "        else:\n",
    "            if (self.training and random.random()<self.clin_dropout) or self.clin_dropout == 1:\n",
    "                #print('ignoring clinical data')\n",
    "                resnet_out = self.model(x_image)\n",
    "                output = self.fc(resnet_out)\n",
    "            elif (self.training and random.random()<self.image_dropout) or self.image_dropout == 1:\n",
    "                #print('ignoring imaging data')\n",
    "                clin_fc_out = self.clin_fc(x_clinical)\n",
    "                output = self.fc(clin_fc_out)\n",
    "            else:\n",
    "                #print('using both clinical and imaging data')\n",
    "                resnet_out = self.model(x_image)\n",
    "                clin_fc_out = self.clin_fc(x_clinical)\n",
    "                output = self.fc(resnet_out+clin_fc_out)\n",
    "            \n",
    "        #output = self.final_activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel_LateFusion(nn.Module):\n",
    "    def __init__(self, base_model,\n",
    "                 output_size,\n",
    "                 num_additional_features,\n",
    "                 clin_dropout = 0,\n",
    "                 image_dropout = 0,\n",
    "                 freeze_image_net = False,\n",
    "                 concatenate_modes = False,\n",
    "                ):\n",
    "        super(RegressionModel_LateFusion, self).__init__()\n",
    "        self.model = base_model\n",
    "        self.model.conv1 = nn.Conv2d(1, self.model.conv1.out_channels,\n",
    "                                     kernel_size=self.model.conv1.kernel_size,\n",
    "                                     stride=self.model.conv1.stride,\n",
    "                                     padding=self.model.conv1.padding,\n",
    "                                     bias=False) \n",
    "\n",
    "        if freeze_image_net:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_resnet_features = self.model.fc.in_features\n",
    "        #print(num_resnet_features)\n",
    "        self.clin_fc = nn.Linear(num_additional_features, num_resnet_features)\n",
    "        #self.fc = nn.Linear(num_resnet_features + num_additional_features, output_size)\n",
    "        self.fc = nn.Linear(num_resnet_features, output_size)\n",
    "        self.model.fc = nn.Identity()\n",
    "        #self.final_activation = nn.LeakyReLU(0.1)\n",
    "        self.clin_dropout = clin_dropout\n",
    "        self.image_dropout = image_dropout\n",
    "        self.concatenate_modes = concatenate_modes \n",
    "        if concatenate_modes:\n",
    "            print(\"concatenating instead of adding.\")\n",
    "            self.fc_con = nn.Linear(num_resnet_features*2, output_size)\n",
    "        \n",
    "    def forward(self, x_image, x_clinical):\n",
    "        if self.concatenate_modes:\n",
    "            resnet_out = self.model(x_image)\n",
    "            clin_fc_out = self.clin_fc(x_clinical)\n",
    "            output = self.fc_con(torch.cat([resnet_out, clin_fc_out], dim =1))\n",
    "        else:\n",
    "            if (self.training and random.random()<self.clin_dropout) or self.clin_dropout == 1:\n",
    "                #print('ignoring clinical data')\n",
    "                resnet_out = self.model(x_image)\n",
    "                output = self.fc(resnet_out)\n",
    "            elif (self.training and random.random()<self.image_dropout) or self.image_dropout == 1:\n",
    "                #print('ignoring imaging data')\n",
    "                clin_fc_out = self.clin_fc(x_clinical)\n",
    "                output = self.fc(clin_fc_out)\n",
    "            else:\n",
    "                #print('using both clinical and imaging data')\n",
    "                resnet_out = self.model(x_image)\n",
    "                clin_fc_out = self.clin_fc(x_clinical)\n",
    "                output = self.fc(resnet_out+clin_fc_out)\n",
    "            \n",
    "        #output = self.final_activation(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LateFusionFC(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(LateFusionFC, self).__init__()\n",
    "        # Define a fully connected layer\n",
    "        self.fc = nn.Linear(2 * n, n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr_ci(x,y,alpha=0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : iterable object such as a list or np.array\n",
    "      Input for correlation calculation\n",
    "    alpha : float\n",
    "      Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "      Pearson's correlation coefficient\n",
    "    pval : float\n",
    "      The corresponding p value\n",
    "    lo, hi : float\n",
    "      The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "\n",
    "    r, p = pearsonr(x,y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(x.size-3)\n",
    "    z = stats.norm.ppf(1-alpha/2)\n",
    "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    return r, p, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_by_name(model_name: str, pretrained=False):\n",
    "    \"\"\"\n",
    "    Returns the corresponding model object given a model name.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_name (str): Name of the model (e.g., 'resnet18', 'resnet50').\n",
    "    - pretrained (bool): If True, returns a model pre-trained on ImageNet. Default is False.\n",
    "    \n",
    "    Returns:\n",
    "    - model: The corresponding PyTorch model.\n",
    "    \"\"\"\n",
    "    model_dict = {\n",
    "        'resnet18': models.resnet18,\n",
    "        'resnet34': models.resnet34,\n",
    "        'resnet50': models.resnet50,\n",
    "        'resnet101': models.resnet101,\n",
    "        'resnet152': models.resnet152,\n",
    "        'alexnet': models.alexnet,\n",
    "        'vgg16': models.vgg16,\n",
    "        'squeezenet': models.squeezenet1_0,\n",
    "        'densenet': models.densenet121,\n",
    "        'inception': models.inception_v3,\n",
    "        'googlenet': models.googlenet,\n",
    "        'shufflenet': models.shufflenet_v2_x1_0,\n",
    "        'mobilenet': models.mobilenet_v2,\n",
    "        'resnext50_32x4d': models.resnext50_32x4d,\n",
    "        'resnext101_32x8d': models.resnext101_32x8d,\n",
    "        'wide_resnet50_2': models.wide_resnet50_2,\n",
    "        'wide_resnet101_2': models.wide_resnet101_2,\n",
    "        'mnasnet': models.mnasnet1_0,\n",
    "        # Add more models as needed\n",
    "    }\n",
    "    \n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f\"Model '{model_name}' is not recognized. Available models are: {list(model_dict.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_weights(model, model_weights: pathlib.Path):\n",
    "    try:\n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            model.module.load_state_dict(torch.load(model_weights, weights_only=True), strict=False)\n",
    "        else:\n",
    "            state_dict = torch.load(model_weights, weights_only=True)\n",
    "            if len(train_df.columns)!=9:\n",
    "                del state_dict['fc.weight']\n",
    "                del state_dict['fc.bias']\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "        print(f'Weights successfully loaded from {model_weights}')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load imaging weights.\\n{e}\")\n",
    "\n",
    "def load_clinical_model_weights(model, clinical_model_weights: pathlib.Path, subset=True):\n",
    "    try:\n",
    "        clinical_state_dict = torch.load(clinical_model_weights, weights_only=True)\n",
    "        \n",
    "        if subset:\n",
    "            clin_fc_state_dict = {k: v for k, v in clinical_state_dict.items() if 'clin_fc' in k}\n",
    "            model.load_state_dict(clin_fc_state_dict, strict =False)\n",
    "        else:\n",
    "            # for late\n",
    "            model.load_state_dict(clinical_state_dict, strict=False)\n",
    "            \n",
    "        print(f'Clinical weights successfully loaded from {clinical_model_weights}')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load clinical weights.\\n{e}\")\n",
    "\n",
    "class SimpleModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def to_device(self, device):\n",
    "        self.model = nn.DataParallel(self.model).to(device)\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, model, inputs, clinical_vars):\n",
    "        return model(inputs, clinical_vars)\n",
    "\n",
    "    def combine(self, all_targets):\n",
    "        return np.concatenate(all_targets, axis=0)\n",
    "\n",
    "class LateModelWrapper:\n",
    "    def __init__(self, imaging_model, clinical_model, model):\n",
    "        self.imaging_model = imaging_model\n",
    "        self.clinical_model = clinical_model\n",
    "        self.model = model\n",
    "\n",
    "    def to_device(self,device):\n",
    "        for param in self.imaging_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.clinical_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model = nn.DataParallel(self.model).to(device)\n",
    "        self.clinical_model = nn.DataParallel(self.clinical_model).to(device)\n",
    "        self.imaging_model = nn.DataParallel(self.imaging_model).to(device)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate(self, model, inputs, clinical_vars):\n",
    "        imaging_outputs = self.imaging_model(inputs, clinical_vars)\n",
    "        clinical_outputs = self.clinical_model(inputs, clinical_vars)\n",
    "        inputs_concat = torch.cat([imaging_outputs, clinical_outputs], dim = 1)\n",
    "        return model(inputs_concat)\n",
    "    \n",
    "    def combine(self, all_targets):\n",
    "        all_targets = np.concatenate(all_targets, axis=0)\n",
    "        return target_scaler.inverse_transform(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with cross-validation\n",
    "def train_and_evaluate(\n",
    "    wrapper: SimpleModelWrapper | LateModelWrapper,\n",
    "    output_folder: pathlib.Path,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    loss,\n",
    "    epochs=25,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    run_name: str = \"\",\n",
    "    batch_size = 16):\n",
    "\n",
    "    if run_name == \"HP_tuning\":\n",
    "        run_name = f\"hp_multimodal_lr-{lr}_wd-{weight_decay}_bs-{batch_size}_resnet18\"\n",
    "\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    output_model_path = output_folder / f\"{run_name}_model.pth\"\n",
    "    if output_model_path.exist():\n",
    "        run_name = f\"{run_name}_1\"\n",
    "        output_model_path = output_folder / f\"{run_name}_model.pth\"\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    model = wrapper.to_device(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = loss()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "    best_corrs = {}\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for input_dict in tqdm(train_loader):\n",
    "            inputs = input_dict['image']\n",
    "            targets = input_dict['target']\n",
    "            clinical_vars = input_dict['clinical']\n",
    "            #clinical_vars = torch.zeros(clinical_vars.shape)\n",
    "            clinical_vars = clinical_vars.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = wrapper.evaluate(model, inputs, clinical_vars)\n",
    "\n",
    "            #if torch.isnan(outputs).any() or torch.isnan(targets).any(): \n",
    "                #print(\"inputs\", inputs, clinical_vars)\n",
    "                #print(\"outputs\", outputs, \"\\ntargets\", targets, \"\\n\")\n",
    "            loss = criterion(outputs, targets)\n",
    "            if torch.isnan(loss).any(): \n",
    "                pass\n",
    "                #print(outputs, targets)\n",
    "            else:\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for input_dict in tqdm(test_loader):\n",
    "                inputs = input_dict['image']\n",
    "                targets = input_dict['target']\n",
    "                clinical_vars = input_dict['clinical']\n",
    "                clinical_vars = clinical_vars.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = wrapper(inputs, clinical_vars)\n",
    "    \n",
    "                #if torch.isnan(outputs).any() or torch.isnan(targets).any(): \n",
    "                    #print(\"inputs\", inputs, clinical_vars)\n",
    "                    #print(\"outputs\", outputs, \"\\ntargets\", targets, \"\\n\")\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "                all_outputs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        best_epoch = False\n",
    "        if test_loss < best_loss:\n",
    "            best_epoch = True\n",
    "            best_loss = test_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                torch.save(model.module.state_dict(), output_model_path)\n",
    "            else:\n",
    "                torch.save(model.state_dict(), output_model_path)\n",
    "\n",
    "\n",
    "        all_targets = wrapper.combine(all_targets)\n",
    "        all_outputs = wrapper.combine(all_outputs)\n",
    "        # Calculate Spearman correlation\n",
    "        spearman_corrs = []\n",
    "        pearson_corrs = []\n",
    "        spearman_pvals = []\n",
    "        pearson_pvals = []\n",
    "        pearson_low = []\n",
    "        pearson_high = []\n",
    "        for i in range(all_targets.shape[1]):\n",
    "            corr, p_val = spearmanr(all_targets[:, i], all_outputs[:, i])\n",
    "            pcorr, pp_val = pearsonr(all_targets[:, i], all_outputs[:, i])\n",
    "            pcorr_v2, p_val_v2, low, high = pearsonr_ci(all_targets[:, i], all_outputs[:, i])\n",
    "            spearman_corrs.append(corr)\n",
    "            pearson_corrs.append(pcorr)\n",
    "            spearman_pvals.append(p_val)\n",
    "            pearson_pvals.append(pp_val)\n",
    "            pearson_low.append(low)\n",
    "            pearson_high.append(high)\n",
    "        #print(f\"Spearman Correlations: {spearman_corrs}\")\n",
    "\n",
    "        clear_output(wait=False)\n",
    "        print(run_name)\n",
    "        \n",
    "        # Plotting 3x3 scatter plot matrix\n",
    "        num_rows = int(np.ceil(all_targets.shape[1]/3))\n",
    "        fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows*5))\n",
    "        axes = axes.flatten()\n",
    "        # Plotting 3x3 scatter plot matrix\n",
    "        for i in range(all_targets.shape[1]):\n",
    "            ax = axes[i]\n",
    "            ax.scatter(all_targets[:, i], all_outputs[:, i], alpha=0.5)\n",
    "            \n",
    "            # Set same scale for both x and y axes\n",
    "            min_val = min(all_targets[:, i].min(), all_outputs[:, i].min())\n",
    "            max_val = max(all_targets[:, i].max(), all_outputs[:, i].max())\n",
    "            ax.set_xlim([min_val, max_val])\n",
    "            ax.set_ylim([min_val, max_val])\n",
    "            \n",
    "            # Draw a regression line\n",
    "            z = np.polyfit(all_targets[:, i], all_outputs[:, i], 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax.plot([min_val, max_val], p([min_val, max_val]), \"r--\")\n",
    "        \n",
    "            ax.set_title(f'{train_dataset.target_cols[i]}\\nTarget vs Prediction\\nSpearman: {spearman_corrs[i]:.2f} ({spearman_pvals[i]:.2f})\\nPearson: {pearson_corrs[i]:.2f} ({pearson_pvals[i]:.2f}, 95CI: {pearson_low[i]:.2f}:{pearson_high[i]:.2f})')\n",
    "            ax.set_xlabel('True Values')\n",
    "            ax.set_ylabel('Predictions')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(all_targets.shape[1], len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_folder / f\"{run_name}Predictions.png\")\n",
    "        if best_epoch: \n",
    "            plt.savefig(output_folder / f\"{run_name}Predictions_Best.png\")\n",
    "            for i, col in enumerate(train_dataset.target_cols):\n",
    "                best_corrs[col] = {\n",
    "                    \"pearson\" : pearson_corrs[i],\n",
    "                    \"spearman\" : spearman_corrs[i],\n",
    "                }\n",
    "            \n",
    "        plt.show()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "        plt.plot(range(len(train_losses)), train_losses, label='Train Loss', color = \"blue\")\n",
    "        plt.plot(range(len(test_losses)), test_losses, label='Test Loss', color = \"red\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(output_folder / f\"{run_name}lossCurves.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        torch.save(model.module.state_dict(),  output_folder/ f\"{run_name}_model_final.pth\")\n",
    "        torch.save(model.module,  output_folder / f\"{run_name}_model_final_full.pth\")\n",
    "    else:\n",
    "        torch.save(model.state_dict(),  output_folder / f\"{run_name}_model_final.pth\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return {\n",
    "        'model' : model,\n",
    "        'best_loss' : best_loss,\n",
    "        'best_corrs' : best_corrs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_loss = nn.SmoothL1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = pathlib.Path(\"./output\")\n",
    "output_size = len(train_minmax_dataset.target_cols)\n",
    "\n",
    "model = RegressionModel_EarlyFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 0.2,\n",
    "    image_dropout = 0,\n",
    ")\n",
    "# load_model_weights(model, output_folder / 'imaging_orig_vol_test_v1_model_final.pth')\n",
    "# load_clinical_model_weights(model, output_folder / 'clinical_orig_vol_test_v1_model_final.pth')\n",
    "\n",
    "trained_model = train_and_evaluate(\n",
    "    SimpleModelWrapper(model),\n",
    "    output_folder,\n",
    "    train_minmax_dataset, \n",
    "    test_minmax_dataset, \n",
    "    loss = huber_loss, \n",
    "    epochs=30, \n",
    "    lr=1e-05, \n",
    "    weight_decay=3.162277660168379e-08, \n",
    "    run_name = \"early_orig_l3_test_v1\",\n",
    "    batch_size = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter clinical only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = pathlib.Path(\"./output\")\n",
    "output_size = len(train_zscore_dataset.target_cols)\n",
    "\n",
    "model = RegressionModel_InterFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 0,\n",
    "    image_dropout = 1,\n",
    "    freeze_image_net = False,\n",
    "    concatenate_modes = False,\n",
    "    )\n",
    "\n",
    "trained_model = train_and_evaluate(\n",
    "    SimpleModelWrapper(model),\n",
    "    output_folder,\n",
    "    train_zscore_dataset, \n",
    "    test_zscore_dataset, \n",
    "    loss = huber_loss, \n",
    "    epochs=10, \n",
    "    lr=1e-4, \n",
    "    weight_decay=1e-8, \n",
    "    run_name = \"clinical_orig_l3_test_v1\",\n",
    "    batch_size = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter Image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = pathlib.Path(\"./output\")\n",
    "output_size = len(train_zscore_dataset.target_cols)\n",
    "\n",
    "model = RegressionModel_InterFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 1,\n",
    "    image_dropout = 0,\n",
    "    freeze_image_net = False,\n",
    "    concatenate_modes = False,\n",
    "    )\n",
    "# load_model_weights(model, pathlib.Path(output_folder / 'image_only_resnet18_scaled_v9_model.pth'))\n",
    "\n",
    "trained_model = train_and_evaluate(\n",
    "    SimpleModelWrapper(model),\n",
    "    output_folder,\n",
    "    train_zscore_dataset, \n",
    "    test_zscore_dataset, \n",
    "    loss = huber_loss, \n",
    "    epochs=23, \n",
    "    lr= 1.584893192461114e-05,\n",
    "    weight_decay= 6.30957344480193e-08,\n",
    "    run_name = \"imaging_orig_l3_test_v1\",\n",
    "    batch_size = 16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = pathlib.Path(\"./output\")\n",
    "output_size = len(train_zscore_dataset.target_cols)\n",
    "\n",
    "model = RegressionModel_InterFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 0,\n",
    "    image_dropout = 0,\n",
    "    freeze_image_net = False,\n",
    "    concatenate_modes = True,\n",
    "    )\n",
    "# load_model_weights(model, pathlib.Path(output_folder / 'imaging_orig_l3_model_final.pth'))\n",
    "load_clinical_model_weights(model, pathlib.Path(output_folder / 'clinical_orig_vol_test_v1_model_final.pth'))\n",
    "\n",
    "trained_model = train_and_evaluate(\n",
    "    SimpleModelWrapper(model),\n",
    "    output_folder,\n",
    "    train_zscore_dataset, \n",
    "    test_zscore_dataset, \n",
    "    loss = huber_loss, \n",
    "    epochs=30, \n",
    "    lr=1.584893192461114e-05, \n",
    "    weight_decay=6.30957344480193e-08, \n",
    "    run_name = \"multimodal_orig_l3_test\",\n",
    "    batch_size = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = pathlib.Path(\"./output\")\n",
    "output_size = len(train_minmax_dataset.target_cols)\n",
    "\n",
    "imaging_model = RegressionModel_LateFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 1,\n",
    "    image_dropout = 0,\n",
    "    freeze_image_net = False,\n",
    "    concatenate_modes = False,\n",
    ")\n",
    "load_model_weights(imaging_model,  output_folder / 'imaging_orig_vol_test_final_v3_model_final.pth')\n",
    "\n",
    "clinical_model = RegressionModel_LateFusion(\n",
    "    get_model_by_name('resnet18'),\n",
    "    output_size,\n",
    "    num_additional_features = 4,\n",
    "    clin_dropout = 0,\n",
    "    image_dropout = 1,\n",
    "    freeze_image_net = False,\n",
    "    concatenate_modes = False,\n",
    ")\n",
    "load_clinical_model_weights(clinical_model,  output_folder / 'clinical_orig_vol_test_v1_model_final.pth', False)\n",
    "\n",
    "model = LateFusionFC(len(targets_df_new.columns))\n",
    "\n",
    "trained_model = train_and_evaluate(\n",
    "    LateModelWrapper(imaging_model, clinical_model, model),\n",
    "    output_folder,\n",
    "    train_minmax_dataset, \n",
    "    test_minmax_dataset, \n",
    "    loss = huber_loss, \n",
    "    epochs=30, \n",
    "    lr=1e-03, \n",
    "    weight_decay=1e-07, \n",
    "    run_name = \"orig_multimodal_late_Vol_repeat_v2\",\n",
    "    batch_size = 16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BodyComp_2",
   "language": "python",
   "name": "bodycomp_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
